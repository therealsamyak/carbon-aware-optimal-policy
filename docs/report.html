<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta name="robots" content="noindex, nofollow" />
    <meta name="googlebot" content="noindex, nofollow" />
    <title>Report - Optimal Charge Security Camera</title>
    <link rel="stylesheet" href="styles.css" />
    <script
      id="MathJax-script"
      async
      src="https://cdn.jsdelivr.net/npm/mathjax@4/tex-mml-chtml.js"
    ></script>
    <link
      rel="stylesheet"
      href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/default.min.css"
    />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script>
      hljs.highlightAll();
    </script>
  </head>
  <body>
    <!-- Top Navigation -->
    <nav class="top-nav">
      <a href="index.html" class="logo">OCS</a>
      <div class="nav-links">
        <a href="index.html">Home</a>
        <a href="report.html" class="active">Report</a>
        <a href="docs.html">Documentation</a>
        <a href="https://github.com/therealsamyak/ECM202A_2025Fall_Project_2" target="_blank"
          >GitHub</a
        >
      </div>
    </nav>

    <div class="layout-container">
      <!-- Sidebar -->
      <aside class="sidebar">
        <h2>Table of Contents</h2>
        <ul class="toc-links">
          <li><a href="#abstract">Abstract</a></li>
          <li><a href="#introduction">1. Introduction</a></li>
          <li><a href="#related-work">2. Related Work</a></li>
          <li><a href="#technical-approach">3. Technical Approach</a></li>
          <li><a href="#evaluation-results">4. Evaluation & Results</a></li>
          <li><a href="#discussion-conclusions">5. Discussion & Conclusions</a></li>
          <li><a href="#references">6. References</a></li>
          <li><a href="#supplementary-material">7. Supplementary Material</a></li>
        </ul>

        <div class="footer-info">
          <p><strong>Contributors:</strong><br />Samyak Kakatur, Jasper Lin</p>
        </div>
      </aside>

      <!-- Main Content -->
      <main class="main-content">
        <div class="content-wrapper">
          <h1>Optimal Charge Security Camera</h1>

          <!-- Abstract Section -->
          <section id="abstract" class="section">
            <h2>Abstract</h2>
            <p>
              Carbon awareness is becoming increasingly important in the modern world, and many
              companies are striving to be carbon-neutral in their operations. Existing research
              into carbon-aware computing has focused on high-power, high-performance computing
              systems, but there has not been any awareness into carbon-aware battery charging,
              especially for small-scale IoT devices. In this paper, we propose a controller
              framework for a battery-powered security camera that balances the tradeoff
              betweenaccuracy, latency, carbon footprint, and charging decisions based on a
              pre-defined reward function. This controller picks the optimal models and when to
              charge every task interval over a horizon of time.
            </p>
          </section>

          <!-- Introduction Section -->
          <section id="introduction" class="section">
            <h2>1. Introduction</h2>

            <h3>1.1 Motivation & Objective</h3>
            <p>
              While significant research has addressed carbon-aware computing in data centers and
              high-performance systems, small-scale IoT devices remain overlooked. Battery-powered
              devices with flexible charging represent a massive, untapped opportunity for carbon
              optimization. If they are plugged in all the time, they can charge even when it is not
              carbon-efficient to do so.
            </p>
            <p>
              Our objective is to develop an intelligent controller that optimizes both
              computational (which model to select) and charging decisions for battery-powered
              security cameras. With this approach, we can charge when it is more carbon-efficient,
              rather than always charging regardless of the carbon cost. We balance our model
              selection to account for this carbon-efficiency
            </p>
            <p>
              Because there are differences of opinion on how much each factor (accuracy, latency,
              carbon footprint, camera uptime) matters to an individual, we define a specific reward
              function that balances these factors. The system supports dynamic weights, so if the
              initial weights are not balanced to a specifc use-case, they are adjustable for other
              use-cases.
            </p>

            <h3>1.2 State of the Art & Its Limitations</h3>
            <p>
              Current carbon-aware research is focused around data-center energy considerations.
              Data centers incur large electricity costs and carbon emissions. There are 2 main
              works related to this:
            </p>
            <ul>
              <li>
                Carbon- and Precedence-Aware Scheduling for Data Processing Clusters<sup
                  id="cite-ref-2"
                  ><a href="#cite-note-2">[2]</a></sup
                >
                - This paper is focused on scheduling data center workloads such that time
                requirements are met, but we delay lower priority tasks to carbon-efficient times.
              </li>
              <li>
                Carbon-Aware Workload Management in Data Centers<sup id="cite-ref-3"
                  ><a href="#cite-note-3">[3]</a></sup
                >
                - This paper is focused on integrating energy components besides the grid, such as
                cooling, heating, solar panels, batteries, energy storage, heat pumps, and heating
                connections to maintain existing data-center workloads while minimizing carbon
                emissions.
              </li>
            </ul>

            <p>
              Both of these papers focus on large scale systems with large scale workloads. These
              approachs are not directly applicable to small-scale IoT devices, which have very
              limited bandwitdh and very small battery capacity (energy storage).
            </p>

            <h3>1.3 Novelty & Rationale</h3>
            <p>
              Our approach relies on imitating an Oracle controller. This Oracle controller can see
              into the future and has full knowledge of the carbon timeseries before it occurs.
              Using that knowledge, we can solve the full discrete MDP based on the system state
              over a given finite horizon of time. We can then train a neural network to imitate
              this Oracle Controller, giving us a controller that can make decisions in real-time.
            </p>

            <p>
              Additionally, as carbon energy generally follows a sinusoidal pattern, we can leverage
              this neural network to also gain insight on the ebb and flow of carbon timeseries,
              further giving us more optimization potential.
            </p>

            <p>
              Finally, by modelling this problem as an MDP (and POMDP), we can take advantage of
              existing solving techniques (ex. Data-driven Planning via Imitation Learning<sup
                id="cite-ref-4"
                ><a href="#cite-note-4">[4]</a></sup
              >), which are well-studied and have multiple proven solutions.
            </p>

            <h3>1.4 Potential Impact</h3>
            <p>
              This system could easily be extended to other battery-powered devices that make
              decisions. Any system with a form of energy storage and energy input can take
              advantage of our models to create their own controllers that balance clean energy.
            </p>

            <h3>1.5 Challenges</h3>
            <p>
              Implementing an energy-aware decision-making controller for battery-powered edge
              devices presents several challenges. The primary difficulty is solving and generating
              sufficient training data from the Oracle MDP, as the state and action spaces grow
              quickly even under coarse discretization. Specific examples include:
            </p>
            <ul>
              <li>
                Deciding how static or dynamic the system should be to user-input. We can allow the
                user to dynamically adjust their requirements during runtime, but adjusting an
                already trained controller could be time-consuming, complex, or expensive,
                especially as we still have to maintain our task interval.
              </li>
              <li>
                Discretization of continuous variables. More precision means more runtime, but too
                much precision can make simple calculations more complex due to floating point
                errors.
              </li>
              <li>
                Carbon patterns vary from region to region. As such, we need to ensure as vast of
                variety carbon data as possible from different times of the year for a complete
                picture.
              </li>
            </ul>

            <h3>1.6 Metrics of Success</h3>
            <p>
              We compare our trained Imitation Controller to the Oracle controller over the
              following metrics:
            </p>
            <ul>
              <li>
                Accuracy - how many times over the horizon does the model selected meet the user's
                requirements?
              </li>
              <ul>
                <li>
                  Success - number of times the selected model met the user's requirements, and had
                  enough energy to run.
                </li>
                <li>
                  Small Miss - number of times the selected model didn't meet the user's
                  requirements, and had enough energy to run.
                </li>
                <li>
                  Failure - number of times a model was unable to run, due to a lack of energy.
                </li>
              </ul>
              <li>
                Utility - differences in the rewards of the Oracle Controller and the Imitation
                Controller decisions over each horizon.
              </li>
              <li>
                "Feasibility-Normalized Effective Uptime" - at each timestep \( t \), let \( F_t \)
                be the set of models feasible under the current energy constraint, and let \( a_t^*
                = \max_{m \in F_t} a(m) \) be the best achievable accuracy. If a model \( m_t \) is
                selected and runs, the timestep is scored as \( \frac{a(m_t)}{a_t^*} \); if no model
                is ran (Failure) it scores a \( 0 \). The metric is computed as the average score
                over the horizon.
              </li>
            </ul>
          </section>

          <!-- Related Work Section -->
          <section id="related-work" class="section">
            <h2>2. Related Work</h2>

            <h3>2.1 Carbon-Aware Computing in Large-Scale Systems</h3>
            <p>
              <strong>Carbon- and Precedence-Aware Scheduling for Data Processing Clusters</strong
              ><sup id="cite-ref-2"><a href="#cite-note-2">[2]</a></sup> developed scheduling
              algorithms that delay lower-priority data center workloads to carbon-efficient times
              while meeting time requirements. The authors focused on large-scale data processing
              clusters with significant energy consumption. While their approach successfully
              reduces carbon emissions in data centers, it assumes substantial energy storage and
              computational resources unavailable to small IoT devices.
            </p>
            <p>
              <strong>Carbon-Aware Workload Management in Data Centers</strong
              ><sup id="cite-ref-3"><a href="#cite-note-3">[3]</a></sup> proposed integrating
              multiple energy components including solar panels, batteries, and energy storage
              systems to minimize carbon emissions while maintaining data center workloads. Their
              multi-energy integration approach is effective for large facilities but requires
              complex infrastructure and significant capital investment, making it unsuitable for
              individual IoT devices.
            </p>

            <h3>2.2 Planning and Control Methods</h3>
            <p>
              <strong>Data-driven Planning via Imitation Learning</strong
              ><sup id="cite-ref-4"><a href="#cite-note-4">[4]</a></sup> introduced a framework for
              training neural networks to imitate optimal planners in complex decision-making
              problems. This paper specifically addresses using imitation learning to solve POMDPs,
              which is directly relevant to our problem. However, this paper is focused on robotics
              planning, and doesn't specifically address planning based on carbon-emissions.
            </p>

            <h3>Other Related Works</h3>
            <p>
              Other works in Section VI are not as directly related to this problem as the other
              papers above are, but still give valuable insight into applications of POMDPs.
            </p>
          </section>

          <!-- Technical Approach Section -->
          <section id="technical-approach" class="section">
            <h2>3. Technical Approach</h2>
            <p>
              Describe your system, methodology, algorithms, and design choices.<br />
              Use figures generously:
            </p>
            <ul>
              <li>System architecture diagram</li>
              <li>Data pipeline</li>
              <li>Algorithm/model block diagram</li>
              <li>Hardware setup photos</li>
            </ul>
            <p>üí° Tip: Add images, diagrams, and code snippets. Make your system reproducible.</p>

            <h3>3.1 Model Profiler</h3>

            <h4>3.1.1 Power and Latency Measurement</h4>
            <p>
              A Model task is defined as loading an image and running the default classifier
              function on it. The task involves:
            </p>

            <p>
              <a
                href="https://github.com/therealsamyak/ECM202A_2025Fall_Project_2/blob/main/model-profiler/power_profiler.py"
                target="_blank"
                >model-profiler/power_profiler.py:277</a
              >
            </p>
            <pre><code>start_time ‚Üê current_time()

FOR i ‚Üê 1 TO iterations DO
    avg_power ‚Üê measure_with_powermetrics(inference_task)
    append avg_power to inference_powers
    sleep for 4 seconds
END FOR

end_time ‚Üê current_time()
total_duration ‚Üê end_time - start_time

total_delay_time ‚Üê iterations x 4.0
actual_inference_duration ‚Üê total_duration - total_delay_time
avg_inference_time_seconds ‚Üê actual_inference_duration / iterations
</code></pre>

            <p>During this task, the power profiler measures:</p>
            <ul>
              <li>
                <strong>Power consumption</strong>: Baseline, idle, and inference power in
                milliwatts using macOS
                <a href="https://ss64.com/mac/powermetrics.html" target="_blank">powermetrics</a>
              </li>
              <li>
                <strong>Energy efficiency</strong>: Energy per inference in mWh calculated from
                power draw and inference time
              </li>
              <li>
                <strong>Performance metrics</strong>: Inference time, success rate, detection count
              </li>
              <li><strong>Model variants</strong>: All YOLOv10 versions (N, S, M, B, L, X)</li>
            </ul>

            <p>
              The profiler uses <code>powermetrics</code> with sudo access to capture CPU/GPU/ANE
              power consumption during the model task, storing results in
              <code>power_profiles.json</code>. Each model is benchmarked across 1000 iterations
              with outlier removal for stable baseline measurements. Time per inference is tracked
              to store latency information alongside power data. Outlier removal trims the top and
              bottom 20% of power readings to eliminate anomalies and uses median values for robust
              statistics.
            </p>

            <h4>3.1.2 Accuracy Dataset Analysis</h4>
            <p>
              Model accuracy values are extracted from the COCO dataset benchmark results stored in
              <a
                href="https://github.com/therealsamyak/ECM202A_2025Fall_Project_2/blob/main/model-profiler/model-data.csv"
                target="_blank"
                >model-data.csv</a
              >. The dataset contains COCO mAP 50-95 scores for each YOLOv10 model variant, provided
              by
              <a href="https://docs.ultralytics.com/models/yolov10/" target="_blank"
                >Ultralytics official documentation</a
              >.
            </p>

            <p>
              The accuracy analysis processes the CSV data to provide approximate accuracy values
              for each YOLOv10 model version, enabling the controller to make informed tradeoffs
              between detection accuracy and energy consumption.
            </p>

            <h3>3.2 System Parameters (per Controller)</h3>

            <p>Let the system parameters be:</p>

            <p>
              \[ \Theta = (B_{\max}, r_{\text{chg}}, \Delta, T, \{d_t\}_{t=0}^{T-1}, u_{\text{acc}},
              u_{\text{lat}}, \mathcal{M}, E(m), W, X, Y, Z) \]
            </p>

            <p>Where:</p>

            <ul>
              <li>\(B_{\max}\) (mWh): maximum battery capacity</li>
              <li>\(\Delta\) (seconds): task interval (e.g., 300s)</li>
              <li>\(T\) (seconds): horizon length</li>
              <li>\(d_t \in [0,1]\): dirty energy fraction at timestep \(t\)</li>
              <li>
                \(\mathcal{M}\): model profile set, where each profile is \((m_{\text{acc}},
                m_{\text{lat}})\) with:
                <ul>
                  <li>
                    \(m_{\text{acc}} \in [0,1]\): model accuracy, where \(\text{MAX\_ACC} = \max_{m
                    \in \mathcal{M}} m_{\text{acc}}\)
                  </li>
                  <li>
                    \(m_{\text{lat}}\) (seconds): model latency, where \(\text{MIN\_LAT} = \min_{m
                    \in \mathcal{M}} m_{\text{lat}}\)
                  </li>
                </ul>
              </li>
              <li>
                \(E(m)\): energy function that maps model \(m\) to its energy consumption in mWh,
                where \(\text{ENERGY\_MIN} = \min_{m \in \mathcal{M}} E(m)\)
              </li>
              <li>
                \(u = (u_{\text{acc}}, u_{\text{lat}}) \in U = \{(u_{\text{acc}}, u_{\text{lat}})
                \in \mathbb{R}^2 \mid u_{\text{acc}} &lt; \text{MAX\_ACC}, u_{\text{lat}} &gt;
                \text{MIN\_LAT}\}\): user requirements, where \(u_{\text{acc}} \in [0,1]\) is the
                accuracy requirement, and \(u_{\text{lat}}\) (seconds) is the latency requirement
              </li>
              <li>\(r_{\text{chg}}\) (mWh/s): battery energy added per second</li>
              <li>
                \(W, X, Y, Z > 0\): reward function weights representing user preferences:
                <ul>
                  <li>\(W\): weight for successfully meeting requirements</li>
                  <li>
                    \(X\): penalty weight for small misses (executed but requirements not met)
                  </li>
                  <li>\(Y\): penalty weight for large misses (no execution)</li>
                  <li>\(Z\): penalty weight for carbon cost</li>
                </ul>
              </li>
            </ul>

            <b
              >To simplify this problem, we assume that ALL these parameters are constant per
              controller. If any of these parameters change, the controller will need to be solved
              and retrained again.</b
            >

            <h3>3.3 Oracle Controller</h3>
            <p>
              The oracle controller has full knowledge of the future carbon trajectory
              \(\{d_t\}_{t=0}^{T-1}\) over the planning horizon.
            </p>

            <h4>State Space</h4>
            <p>
              \[ {s} = (t, B_t) \in \mathcal{S} = \{(t, B_t) \mid t \in \{0,\ldots,T-1\},\; B_t \in
              [0, B_{\max}]\} \]
            </p>
            <p>
              Where \(t\) denotes the current timestep index and \(B_t\) (mWh) denotes the current
              battery level.
            </p>
            <p>
              This state representation is minimal: it includes exactly the variables that affect
              future feasibility and decision-making. In particular, the oracle's knowledge of the
              carbon trajectory is encoded implicitly through the timestep index \(t\), as the dirty
              energy fraction \(d_t\) is a known exogenous function of time.
            </p>

            <h4>Action Space</h4>
            <p>
              \[ a_t = (m_t, c_t) \in \mathcal{A} = (\mathcal{M} \cup \{\varnothing\}) \times
              \{0,1\} \]
            </p>
            <p>
              Each action is \(a_t = (m_t, c_t)\), where \(m_t\) is the model selected for execution
              (or \(\varnothing\) if no model is executed), and \(c_t\) indicates whether the system
              charges during the current task interval.
            </p>

            <h4>Transition Probability</h4>
            <p>
              Given state \(s_t = (t, B_t)\) and action \(a_t = (m_t, c_t)\), the transition
              probability to successor state \(s_{t+1} = (t', B')\) is defined as:
            </p>
            <p>
              \[ P(s_{t+1} \mid s_t, a_t) = \begin{cases} 1 & \text{if } t' = t + 1, B_t + c_t \cdot
              r_{\text{chg}} \ge E(m_t), B' = \min\!\left(B_{\max},\, B_t + c_t \cdot r_{\text{chg}}
              - E(m_t)\right)\\[6pt] 0 & \text{otherwise.} \end{cases} \]
            </p>
            <p>
              Thus, all feasible actions induce a deterministic transition with probability one,
              while actions that would result in negative battery energy are assigned zero
              probability and are therefore infeasible.
            </p>

            <h4>Reward Function</h4>
            <p>
              At each timestep, the environment produces outcome indicators based on the chosen
              action:
            </p>
            <ul>
              <li>
                \( \text{success}_t = \mathbf{1}\{m_t \neq \varnothing \wedge \text{acc}(m_t) \ge
                u_{\text{acc}} \wedge \text{lat}(m_t) \le u_{\text{lat}}\} \)
              </li>
              <li>
                \( \text{small\_miss}_t = \mathbf{1}\{m_t \neq \varnothing \wedge (\text{acc}(m_t) <
                u_{\text{acc}} \vee \text{lat}(m_t) > u_{\text{lat}})\} \)
              </li>
              <li>\( \text{large\_miss}_t = \mathbf{1}\{m_t = \varnothing\} \)</li>
            </ul>
            <p>The dirty energy incurred at timestep \(t\) is:</p>
            <p>\[ \Delta D_t = (E(m_t) + c_t \cdot r_{\text{chg}})\cdot d_t. \]</p>
            <p>The immediate reward is defined as:</p>
            <p>
              \[ R(s_t,a_t,s_{t+1}) = W \cdot \text{success}_t - X \cdot \text{small\_miss}_t - Y
              \cdot \text{large\_miss}_t - Z \cdot \Delta D_t. \]
            </p>
            <p>
              The optimization objective is to maximize the <em>cumulative</em> reward over the
              planning horizon. As a result, the total contribution of successes, misses, and carbon
              cost depends only on their aggregate counts and total dirty energy consumed, not on
              the specific timesteps at which they occur. In particular, for fixed carbon intensity,
              a success followed by a miss yields the same cumulative reward as a miss followed by a
              success, and the timing of a success within the horizon does not affect its
              contribution as long as feasibility is maintained.
            </p>
            <p>
              Importantly, cumulative quantities such as total successes, misses, or dirty energy
              consumed are <em>not</em> included in the state. These quantities enter the objective
              exclusively through the cumulative sum of per-step rewards and do not influence future
              system dynamics or feasibility. Because carbon cost is modeled as a soft penalty and
              does not constrain future actions, histories that reach the same state \((t,B_t)\)
              differ only by an additive constant in accumulated reward. Consequently, the optimal
              continuation from a given state depends solely on the remaining horizon and current
              battery level, preserving the Markov property without explicitly storing historical
              metrics in the state.
            </p>

            <h4>Objective</h4>
            <p>The oracle policy \(\pi^*\) maximizes the cumulative reward over the horizon:</p>
            <p>\[ \pi^* = \arg\max_{\pi} \sum_{t=0}^{T-1} R(s_t, \pi(s_t), s_{t+1}). \]</p>
            <p>This optimization is solved exactly using finite-horizon dynamic programming.</p>

            <!-- <h3>3.1 System Architecture</h3>
            <p>Include a block diagram or pipeline figure.</p>

            <h3>3.2 Data Pipeline</h3>
            <p>Explain how data is collected, processed, and used.</p>

            <h3>3.3 Algorithm / Model Details</h3>
            <p>Use math, pseudocode, or diagrams as needed.</p>

            <h3>3.4 Hardware / Software Implementation</h3>
            <p>Explain equipment, libraries, or frameworks.</p>

            <h3>3.5 Key Design Decisions & Rationale</h3>
            <p>Describe the main design decisions you made.</p> -->
          </section>

          <!-- Evaluation & Results Section -->
          <section id="evaluation-results" class="section">
            <h2>4. Evaluation & Results</h2>
            <p>
              Present experimental results with clarity and professionalism.<br /><br />
              Include:
            </p>
            <ul>
              <li>Plots (accuracy, latency, energy, error curves)</li>
              <li>Tables (comparisons with baselines)</li>
              <li>
                Qualitative visualizations (spectrograms, heatmaps, bounding boxes, screenshots)
              </li>
              <li>Ablation studies</li>
              <li>Error analysis / failure cases</li>
            </ul>
            <p>Each figure should have a caption and a short interpretation.</p>
          </section>

          <!-- Discussion & Conclusions Section -->
          <section id="discussion-conclusions" class="section">
            <h2>5. Discussion & Conclusions</h2>
            <p>
              Synthesize the main insights from your work.<br /><br />
              <strong>What worked well and why?</strong><br />
              <strong>What didn't work and why?</strong><br />
              <strong>What limitations remain?</strong><br />
              <strong>What would you explore next if you had more time?</strong><br /><br />
              This should synthesize‚Äînot merely repeat‚Äîyour results.
            </p>
          </section>

          <!-- References Section -->
          <section id="references" class="section">
            <h2>6. References</h2>
            <p>
              Provide full citations for all sources (academic papers, websites, etc.) referenced
              and all software and datasets uses.
            </p>

            <h3 id="cite-note-4">Data-driven Planning via Imitation Learning<cite>[4]</cite></h3>
            <p>
              Choudhury, S., Bhardwaj, M., Arora, S., Kapoor, A., Ranade, G., Scherer, S., & Dey, D.
              Data-driven Planning via Imitation Learning. The Robotics Institute, Carnegie Mellon
              University & Microsoft Research.
              <a href="https://arxiv.org/abs/2008.09719" target="_blank">[Paper]</a>
            </p>

            <h3 id="cite-note-2">
              Carbon- and Precedence-Aware Scheduling for Data Processing Clusters<cite>[2]</cite>
            </h3>
            <p>
              Lechowicz, A., Shenoy, R., Bashir, N., Hajiesmaili, M., Wierman, A., & Delimitrou, C.
              Carbon- and Precedence-Aware Scheduling for Data Processing Clusters.
              arXiv:2502.09717, 2025.
              <a href="https://arxiv.org/abs/2502.09717" target="_blank">[Paper]</a>
            </p>

            <h3 id="cite-note-3">
              Carbon-Aware Workload Management in Data Centers<cite>[3]</cite>
            </h3>
            <p>
              Nkwawir, B.W., Kayalica, M.O., Guven, D., Duman, A.C., & Erden, H.S. Carbon-Aware
              Workload Management in Data Centers: A Multi-Energy Integration Approach. In
              Proceedings of 16th ACM International Conference on Future and Sustainable Energy
              Systems (E-Energy '25), Association for Computing Machinery, New York, NY, USA,
              907-914.
              <a href="https://doi.org/10.1145/3679240.3735104" target="_blank">[Paper]</a>
            </p>

            <h3 id="cite-note-5">Monte-Carlo Planning in Large POMDPs<cite>[5]</cite></h3>
            <p>
              Silver, D., & Veness, J. Monte-Carlo Planning in Large POMDPs. MIT & UNSW, Sydney,
              Australia.
              <a
                href="https://davidstarsilver.wordpress.com/wp-content/uploads/2025/04/monte-carlo-planning-in-large-pomdps.pdf"
                target="_blank"
                >[Paper]</a
              >
            </p>

            <h3 id="cite-note-6">
              Optimal Control of Markov Processes with Incomplete State Information I<cite
                >[6]</cite
              >
            </h3>
            <p>
              √Östr√∂m, K.J. Optimal Control of Markov Processes with Incomplete State Information I.
              In Journal of Mathematical Analysis and Applications 10. p.174-205, 1965.
              <a href="https://lup.lub.lu.se/record/8867084" target="_blank">[Paper]</a>
            </p>
          </section>

          <!-- Supplementary Material Section -->
          <section id="supplementary-material" class="section">
            <h2>7. Supplementary Material</h2>

            <h3>7.a. Datasets</h3>
            <p>Describe each dataset:</p>
            <ul>
              <li>Source and URL</li>
              <li>Data format</li>
              <li>Preprocessing steps</li>
              <li>Labeling/annotation efforts</li>
            </ul>
            <p>Include your internal dataset if you collected one.</p>

            <h3>7.b. Software</h3>
            <p>List:</p>
            <ul>
              <li>External libraries or models</li>
              <li>Internal modules you wrote</li>
              <li>Links to repos or documentation</li>
            </ul>
          </section>
        </div>
      </main>
    </div>

    <script src="script.js"></script>
  </body>
</html>
